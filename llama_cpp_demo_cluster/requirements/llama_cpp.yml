name: llama_cpp
channels:
  - conda-forge
  - defaults
  - https://repo.anaconda.com/pkgs/main
  - https://repo.anaconda.com/pkgs/r
dependencies:
  - appnope=0.1.4=pyhd8ed1ab_1
  - asttokens=3.0.0=pyhd8ed1ab_1
  - bzip2=1.0.8=h80987f9_6
  - ca-certificates=2024.12.14=hf0a4a13_0
  - comm=0.2.2=pyhd8ed1ab_1
  - debugpy=1.6.7=py312h313beb8_0
  - decorator=5.1.1=pyhd8ed1ab_1
  - exceptiongroup=1.2.2=pyhd8ed1ab_1
  - executing=2.1.0=pyhd8ed1ab_1
  - expat=2.6.4=h313beb8_0
  - importlib-metadata=8.5.0=pyha770c72_1
  - ipykernel=6.29.5=pyh57ce528_0
  - ipython=8.30.0=pyh707e725_0
  - jedi=0.19.2=pyhd8ed1ab_1
  - jupyter_client=8.6.3=pyhd8ed1ab_1
  - jupyter_core=5.7.2=pyh31011fe_1
  - libcxx=14.0.6=h848a8c0_0
  - libffi=3.4.4=hca03da5_1
  - libsodium=1.0.18=h27ca646_1
  - matplotlib-inline=0.1.7=pyhd8ed1ab_1
  - ncurses=6.4=h313beb8_0
  - nest-asyncio=1.6.0=pyhd8ed1ab_1
  - openssl=3.4.0=h39f12f2_0
  - packaging=24.2=pyhd8ed1ab_2
  - parso=0.8.4=pyhd8ed1ab_1
  - pexpect=4.9.0=pyhd8ed1ab_1
  - pickleshare=0.7.5=pyhd8ed1ab_1004
  - pip=24.2=py312hca03da5_0
  - platformdirs=4.3.6=pyhd8ed1ab_1
  - prompt-toolkit=3.0.48=pyha770c72_1
  - psutil=5.9.0=py312h80987f9_0
  - ptyprocess=0.7.0=pyhd8ed1ab_1
  - pure_eval=0.2.3=pyhd8ed1ab_1
  - pygments=2.18.0=pyhd8ed1ab_1
  - python=3.12.8=h99e199e_0
  - python-dateutil=2.9.0.post0=pyhff2d567_1
  - pyzmq=25.1.2=py312h313beb8_0
  - readline=8.2=h1a28f6b_0
  - setuptools=75.1.0=py312hca03da5_0
  - six=1.17.0=pyhd8ed1ab_0
  - sqlite=3.45.3=h80987f9_0
  - stack_data=0.6.3=pyhd8ed1ab_1
  - tk=8.6.14=h6ba3021_0
  - tornado=6.4.2=py312h80987f9_0
  - traitlets=5.14.3=pyhd8ed1ab_1
  - typing_extensions=4.12.2=pyha770c72_1
  - wcwidth=0.2.13=pyhd8ed1ab_1
  - wheel=0.44.0=py312hca03da5_0
  - xz=5.4.6=h80987f9_1
  - zeromq=4.3.5=h313beb8_0
  - zipp=3.21.0=pyhd8ed1ab_1
  - zlib=1.2.13=h18a0788_1
  - pip:
      - certifi==2024.12.14
      - charset-normalizer==3.4.0
      - diskcache==5.6.3
      - filelock==3.16.1
      - fsspec==2024.10.0
      - gguf==0.13.0
      - huggingface-hub==0.27.0
      - idna==3.10
      - jinja2==3.1.4
      - llama-cpp-python==0.3.7
      - markupsafe==3.0.2
      - mpmath==1.3.0
      - networkx==3.4.2
      - numpy==1.26.4
      - pandas==2.2.3
      - protobuf==4.25.5
      - pytz==2025.1
      - pyyaml==6.0.2
      - regex==2024.11.6
      - requests==2.32.3
      - safetensors==0.4.5
      - sentencepiece==0.2.0
      - sympy==1.13.3
      - tokenizers==0.21.0
      - torch==2.2.2
      - tqdm==4.67.1
      - transformers==4.47.1
      - tzdata==2025.1
      - urllib3==2.2.3
prefix: /opt/anaconda3/envs/llama_cpp
